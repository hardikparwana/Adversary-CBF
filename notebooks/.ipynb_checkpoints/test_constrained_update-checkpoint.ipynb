{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a925266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hardik/Desktop/Research/Adversary-CBF/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfea877f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17 % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993b6629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17 != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a4207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad5e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.copy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc08844",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4180d39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db8b2879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99899998])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = cp.Variable(1)\n",
    "p = cp.Parameter(1)\n",
    "quadratic = cp.square(x)\n",
    "p.value = np.array([0.001])\n",
    "const = [x <= 1]\n",
    "const += [x >= 1 - p]\n",
    "problem = cp.Problem(cp.Minimize(quadratic), const)\n",
    "problem.solve(requires_grad=True)\n",
    "x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dcef779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient is [-0.99999985].\n"
     ]
    }
   ],
   "source": [
    "problem.backward()\n",
    "print(\"The gradient is {}.\".format(p.gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c6c089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99999974])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd998412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0+cu102'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0e1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd277959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(a,a-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5493febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "28690fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4a72f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor(np.array([1,2]))\n",
    "x = torch.tensor([2,2],requires_grad=True,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "46fab5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x[0] #torch.square(x[0]) * 5\n",
    "b = torch.tensor([[3]],requires_grad=True,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a1e5fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.cat((a.reshape((1,1)),b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "4a6f7bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [3.]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "32534afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "a56cfa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.enable_grad():\n",
    "    a.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a5ee4d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "495582f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21.,  0.])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3863ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].grad\n",
    "preds = model(testX)\n",
    "f_mean = f_preds.mean\n",
    "f_covar = f_preds.covariance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "bbe07531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "a8f99860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/30 - Loss: 0.954   lengthscale: 0.693   noise: 0.693\n",
      "Iter 2/30 - Loss: 0.923   lengthscale: 0.644   noise: 0.644\n",
      "Iter 3/30 - Loss: 0.888   lengthscale: 0.598   noise: 0.598\n",
      "Iter 4/30 - Loss: 0.849   lengthscale: 0.555   noise: 0.554\n",
      "Iter 5/30 - Loss: 0.805   lengthscale: 0.514   noise: 0.513\n",
      "Iter 6/30 - Loss: 0.755   lengthscale: 0.475   noise: 0.474\n",
      "Iter 7/30 - Loss: 0.700   lengthscale: 0.439   noise: 0.437\n",
      "Iter 8/30 - Loss: 0.644   lengthscale: 0.405   noise: 0.402\n",
      "Iter 9/30 - Loss: 0.590   lengthscale: 0.372   noise: 0.369\n",
      "Iter 10/30 - Loss: 0.541   lengthscale: 0.342   noise: 0.339\n",
      "Iter 11/30 - Loss: 0.497   lengthscale: 0.315   noise: 0.310\n",
      "Iter 12/30 - Loss: 0.457   lengthscale: 0.291   noise: 0.283\n",
      "Iter 13/30 - Loss: 0.420   lengthscale: 0.271   noise: 0.259\n",
      "Iter 14/30 - Loss: 0.384   lengthscale: 0.254   noise: 0.236\n",
      "Iter 15/30 - Loss: 0.349   lengthscale: 0.241   noise: 0.215\n",
      "Iter 16/30 - Loss: 0.314   lengthscale: 0.230   noise: 0.196\n",
      "Iter 17/30 - Loss: 0.280   lengthscale: 0.221   noise: 0.178\n",
      "Iter 18/30 - Loss: 0.245   lengthscale: 0.215   noise: 0.162\n",
      "Iter 19/30 - Loss: 0.211   lengthscale: 0.211   noise: 0.147\n",
      "Iter 20/30 - Loss: 0.178   lengthscale: 0.208   noise: 0.133\n",
      "Iter 21/30 - Loss: 0.144   lengthscale: 0.207   noise: 0.121\n",
      "Iter 22/30 - Loss: 0.111   lengthscale: 0.208   noise: 0.110\n",
      "Iter 23/30 - Loss: 0.079   lengthscale: 0.210   noise: 0.100\n",
      "Iter 24/30 - Loss: 0.048   lengthscale: 0.213   noise: 0.090\n",
      "Iter 25/30 - Loss: 0.018   lengthscale: 0.217   noise: 0.082\n",
      "Iter 26/30 - Loss: -0.010   lengthscale: 0.223   noise: 0.075\n",
      "Iter 27/30 - Loss: -0.036   lengthscale: 0.229   noise: 0.068\n",
      "Iter 28/30 - Loss: -0.060   lengthscale: 0.237   noise: 0.062\n",
      "Iter 29/30 - Loss: -0.082   lengthscale: 0.245   noise: 0.057\n",
      "Iter 30/30 - Loss: -0.101   lengthscale: 0.254   noise: 0.052\n"
     ]
    }
   ],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "training_iter = 30\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6a7453fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "dfb60a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(0, 1, 51, requires_grad=True)\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "60ae41d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "69618df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 51])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_pred.covariance_matrix[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "11b8b83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 51])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_x).covariance_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "37bb4263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0567,  0.1624,  0.2707,  0.3795,  0.4868,  0.5905,  0.6884,  0.7784,\n",
       "         0.8585,  0.9270,  0.9820,  1.0223,  1.0468,  1.0545,  1.0451,  1.0184,\n",
       "         0.9747,  0.9145,  0.8386,  0.7484,  0.6453,  0.5310,  0.4075,  0.2768,\n",
       "         0.1413,  0.0033, -0.1349, -0.2709, -0.4023, -0.5270, -0.6426, -0.7474,\n",
       "        -0.8394, -0.9173, -0.9796, -1.0255, -1.0542, -1.0655, -1.0592, -1.0358,\n",
       "        -0.9960, -0.9407, -0.8712, -0.7892, -0.6964, -0.5949, -0.4868, -0.3743,\n",
       "        -0.2596, -0.1451, -0.0327], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood(model(test_x)).mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea7b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "308102b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x =  torch.cat ( (torch.linspace(0, 1, 100).reshape(-1,1),  torch.linspace(-0.5, 0.5, 100).reshape(-1,1)), 1 )\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x[:,0] * (2 * math.pi)) + train_x[:,1] * 3 +  torch.randn(train_x.size()[0]) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "15941f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9435e+00, -1.6642e+00, -1.3885e+00, -9.1477e-01, -8.9229e-01,\n",
       "        -1.2218e+00, -9.8330e-01, -1.3705e+00, -8.0258e-01, -4.7033e-01,\n",
       "        -6.1223e-01, -3.9923e-01, -6.0768e-01, -6.8359e-01, -2.5790e-02,\n",
       "        -5.2378e-01, -6.0159e-02, -8.7785e-02, -1.6056e-01,  8.4152e-02,\n",
       "         1.2648e-01,  1.8063e-01,  4.9475e-01,  9.3538e-02,  3.4815e-01,\n",
       "         4.5323e-01,  2.5936e-01,  3.4477e-01,  3.2682e-01,  2.8664e-01,\n",
       "         4.0270e-01,  5.4730e-01,  6.0069e-01,  6.0073e-01,  3.8974e-01,\n",
       "         1.8194e-01,  3.0586e-01,  3.3457e-01,  3.9940e-01, -6.8730e-03,\n",
       "         2.2894e-01,  1.3164e-01,  4.5387e-01,  2.6800e-01,  1.4775e-01,\n",
       "         3.1796e-01,  5.7168e-04,  1.9722e-01,  4.6249e-01, -6.7449e-02,\n",
       "        -1.3187e-01, -1.8685e-01, -5.4136e-01, -3.9378e-01,  2.8493e-01,\n",
       "         4.6386e-02, -3.0435e-01, -1.1964e-01, -6.5248e-02, -9.7795e-02,\n",
       "        -3.0824e-01, -1.4589e-01, -4.5584e-01, -1.9308e-01, -1.0430e-01,\n",
       "        -3.1927e-01, -2.7763e-01, -3.8075e-03, -3.1990e-01, -5.2605e-01,\n",
       "        -4.2528e-01, -2.1438e-01,  8.5909e-02, -1.3651e-01, -1.5532e-01,\n",
       "        -1.4905e-01, -2.4878e-01, -3.1540e-01, -8.6207e-02,  7.5936e-02,\n",
       "        -1.6345e-01, -1.4696e-01,  8.1797e-03,  3.7329e-01,  4.0507e-01,\n",
       "         1.3834e-01,  4.9322e-01,  7.2264e-01,  8.5900e-01,  1.0777e+00,\n",
       "         9.4737e-01,  6.9152e-01,  8.1031e-01,  8.5715e-01,  9.0524e-01,\n",
       "         7.9825e-01,  1.2451e+00,  1.1646e+00,  1.3745e+00,  1.6004e+00])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a68605b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f51ced30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/30 - Loss: 0.396   lengthscale: 0.693   noise: 0.048\n",
      "Iter 2/30 - Loss: 0.398   lengthscale: 0.693   noise: 0.045\n",
      "Iter 3/30 - Loss: 0.401   lengthscale: 0.693   noise: 0.042\n",
      "Iter 4/30 - Loss: 0.405   lengthscale: 0.693   noise: 0.039\n",
      "Iter 5/30 - Loss: 0.410   lengthscale: 0.693   noise: 0.037\n",
      "Iter 6/30 - Loss: 0.415   lengthscale: 0.693   noise: 0.036\n",
      "Iter 7/30 - Loss: 0.420   lengthscale: 0.693   noise: 0.034\n",
      "Iter 8/30 - Loss: 0.424   lengthscale: 0.693   noise: 0.034\n",
      "Iter 9/30 - Loss: 0.427   lengthscale: 0.693   noise: 0.033\n",
      "Iter 10/30 - Loss: 0.428   lengthscale: 0.693   noise: 0.033\n",
      "Iter 11/30 - Loss: 0.429   lengthscale: 0.693   noise: 0.032\n",
      "Iter 12/30 - Loss: 0.429   lengthscale: 0.693   noise: 0.032\n",
      "Iter 13/30 - Loss: 0.427   lengthscale: 0.693   noise: 0.033\n",
      "Iter 14/30 - Loss: 0.425   lengthscale: 0.693   noise: 0.033\n",
      "Iter 15/30 - Loss: 0.422   lengthscale: 0.693   noise: 0.034\n",
      "Iter 16/30 - Loss: 0.419   lengthscale: 0.693   noise: 0.035\n",
      "Iter 17/30 - Loss: 0.416   lengthscale: 0.693   noise: 0.036\n",
      "Iter 18/30 - Loss: 0.412   lengthscale: 0.693   noise: 0.037\n",
      "Iter 19/30 - Loss: 0.409   lengthscale: 0.693   noise: 0.038\n",
      "Iter 20/30 - Loss: 0.406   lengthscale: 0.693   noise: 0.039\n",
      "Iter 21/30 - Loss: 0.404   lengthscale: 0.693   noise: 0.040\n",
      "Iter 22/30 - Loss: 0.402   lengthscale: 0.693   noise: 0.041\n",
      "Iter 23/30 - Loss: 0.400   lengthscale: 0.693   noise: 0.043\n",
      "Iter 24/30 - Loss: 0.399   lengthscale: 0.693   noise: 0.044\n",
      "Iter 25/30 - Loss: 0.398   lengthscale: 0.693   noise: 0.045\n",
      "Iter 26/30 - Loss: 0.397   lengthscale: 0.693   noise: 0.046\n",
      "Iter 27/30 - Loss: 0.397   lengthscale: 0.693   noise: 0.048\n",
      "Iter 28/30 - Loss: 0.396   lengthscale: 0.693   noise: 0.049\n",
      "Iter 29/30 - Loss: 0.396   lengthscale: 0.693   noise: 0.050\n",
      "Iter 30/30 - Loss: 0.396   lengthscale: 0.693   noise: 0.051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "training_iter = 30\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f9a68ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.tensor( np.append( np.linspace(0,1,51).reshape(-1,1), np.linspace(-0.5,0.5,51).reshape(-1,1) , axis=1)  , requires_grad=True, dtype=torch.float)\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "255e7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.tensor( np.append( np.linspace(0,1,51).reshape(-1,1), np.linspace(-0.5,0.5,51).reshape(-1,1) , axis=1)  , requires_grad=True, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7674ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hardik/Desktop/Research/Adversary-CBF/venv/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([100]))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "65ec2fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([51]))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "dea334e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9660c54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3744, -1.2036, -1.0377, -0.8780, -0.7257, -0.5818, -0.4473, -0.3231,\n",
       "        -0.2098, -0.1082, -0.0186,  0.0588,  0.1236,  0.1761,  0.2163,  0.2447,\n",
       "         0.2618,  0.2681,  0.2645,  0.2520,  0.2315,  0.2042,  0.1714,  0.1343,\n",
       "         0.0943,  0.0528,  0.0112, -0.0292, -0.0670, -0.1008, -0.1293, -0.1515,\n",
       "        -0.1662, -0.1724, -0.1694, -0.1563, -0.1325, -0.0978, -0.0517,  0.0059,\n",
       "         0.0749,  0.1551,  0.2462,  0.3477,  0.4591,  0.5795,  0.7082,  0.8441,\n",
       "         0.9862,  1.1335,  1.2847], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_pred.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "90976939",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_pred.mean[0].sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "8fbd7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5c888dfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [270]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Research/Adversary-CBF/venv/lib/python3.8/site-packages/numpy/lib/function_base.py:5392\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5390\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[1;32m   5391\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "a = np.append(a,np.array([1,2]).reshape(-1,1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "239dde1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7bdfd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.append( np.ones((2,2)), np.zeros((2,2)), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "62b85c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0.])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9babc932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0.])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "bc96d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ebd8a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "type(a)==int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c425ecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 'hello'\n",
    "type(b)==str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3ef064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid copying things to GPU memory,\n",
    "# ideally allocate everything in torch on the GPU\n",
    "# and avoid non-torch function calls\n",
    "import torch\n",
    "from torchquad import MonteCarlo, set_up_backend\n",
    "\n",
    "#export CUDA_VISIBLE_DEVICES=\"\"\n",
    "# Enable GPU support if available and set the floating point precision\n",
    "# set_up_backend(\"torch\", data_type=\"float32\")\n",
    "\n",
    "# The function we want to integrate, in this example\n",
    "# f(x0,x1) = sin(x0) + e^x1 for x0=[0,1] and x1=[-1,1]\n",
    "# Note that the function needs to support multiple evaluations at once (first\n",
    "# dimension of x here)\n",
    "# Expected result here is ~3.2698\n",
    "def some_function(x):\n",
    "    return torch.sin(x[:, 0]) + torch.exp(x[:, 1])\n",
    "\n",
    "# Declare an integrator;\n",
    "# here we use the simple, stochastic Monte Carlo integration method\n",
    "mc = MonteCarlo()\n",
    "\n",
    "# Compute the function integral by sampling 10000 points over domain\n",
    "integral_value = mc.integrate(\n",
    "    some_function,\n",
    "    dim=2,\n",
    "    N=10000,\n",
    "    integration_domain=[[0, 1], [-1, 1]],\n",
    "    backend=\"torch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2337d85",
   "metadata": {},
   "source": [
    "### Multivariate GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc85fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f1624",
   "metadata": {},
   "source": [
    "### Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb54dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(0, 1, 100)\n",
    "\n",
    "train_y = torch.stack([\n",
    "    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\n",
    "    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\n",
    "], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64056675",
   "metadata": {},
   "source": [
    "### MultiVariate GPP class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01594604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=2\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.RBFKernel(), num_tasks=2, rank=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd718d",
   "metadata": {},
   "source": [
    "### Train Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "154cfec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 0.011\n",
      "Iter 2/50 - Loss: 0.000\n",
      "Iter 3/50 - Loss: -0.006\n",
      "Iter 4/50 - Loss: -0.008\n",
      "Iter 5/50 - Loss: -0.006\n",
      "Iter 6/50 - Loss: -0.005\n",
      "Iter 7/50 - Loss: -0.003\n",
      "Iter 8/50 - Loss: -0.003\n",
      "Iter 9/50 - Loss: -0.004\n",
      "Iter 10/50 - Loss: -0.005\n",
      "Iter 11/50 - Loss: -0.007\n",
      "Iter 12/50 - Loss: -0.008\n",
      "Iter 13/50 - Loss: -0.008\n",
      "Iter 14/50 - Loss: -0.008\n",
      "Iter 15/50 - Loss: -0.008\n",
      "Iter 16/50 - Loss: -0.007\n",
      "Iter 17/50 - Loss: -0.007\n",
      "Iter 18/50 - Loss: -0.007\n",
      "Iter 19/50 - Loss: -0.007\n",
      "Iter 20/50 - Loss: -0.007\n",
      "Iter 21/50 - Loss: -0.008\n",
      "Iter 22/50 - Loss: -0.008\n",
      "Iter 23/50 - Loss: -0.008\n",
      "Iter 24/50 - Loss: -0.008\n",
      "Iter 25/50 - Loss: -0.008\n",
      "Iter 26/50 - Loss: -0.008\n",
      "Iter 27/50 - Loss: -0.008\n",
      "Iter 28/50 - Loss: -0.008\n",
      "Iter 29/50 - Loss: -0.008\n",
      "Iter 30/50 - Loss: -0.008\n",
      "Iter 31/50 - Loss: -0.008\n",
      "Iter 32/50 - Loss: -0.008\n",
      "Iter 33/50 - Loss: -0.008\n",
      "Iter 34/50 - Loss: -0.008\n",
      "Iter 35/50 - Loss: -0.008\n",
      "Iter 36/50 - Loss: -0.008\n",
      "Iter 37/50 - Loss: -0.008\n",
      "Iter 38/50 - Loss: -0.008\n",
      "Iter 39/50 - Loss: -0.008\n",
      "Iter 40/50 - Loss: -0.008\n",
      "Iter 41/50 - Loss: -0.008\n",
      "Iter 42/50 - Loss: -0.008\n",
      "Iter 43/50 - Loss: -0.008\n",
      "Iter 44/50 - Loss: -0.008\n",
      "Iter 45/50 - Loss: -0.008\n",
      "Iter 46/50 - Loss: -0.008\n",
      "Iter 47/50 - Loss: -0.008\n",
      "Iter 48/50 - Loss: -0.008\n",
      "Iter 49/50 - Loss: -0.008\n",
      "Iter 50/50 - Loss: -0.008\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iterations = 2 if smoke_test else 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ccee1",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c02e61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "test_x = torch.tensor([3], dtype=torch.float, requires_grad=True)\n",
    "predictions = model(test_x)\n",
    "mu = predictions.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b83b8c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.backward of tensor(0.2173, grad_fn=<SumBackward0>)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.sum().backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16425a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2358e-12])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e2b2793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0149, 0.2024]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96728c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu tensor([[0.0149, 0.2024]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m mu2 \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mmean\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmu\u001b[39m\u001b[38;5;124m\"\u001b[39m, mu)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmu2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_x2\u001b[38;5;241m.\u001b[39mgrad)\n",
      "File \u001b[0;32m~/Desktop/Research/Adversary-CBF/venv/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Research/Adversary-CBF/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "with gpytorch.settings.fast_pred_var():\n",
    "    test_x2 = torch.tensor([51], dtype=torch.float, requires_grad=True)\n",
    "    predictions2 = model(test_x2)\n",
    "    mu2 = predictions.mean\n",
    "    print(\"mu\", mu)\n",
    "    mu2.sum().backward()\n",
    "    print(\"test grad\", test_x2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd9ae971",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m f, (y1_ax, y2_ax) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\u001b[38;5;66;03m#torch.no_grad(), gpytorch.settings.fast_pred_var():\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     test_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m51\u001b[39m)\n\u001b[1;32m     11\u001b[0m     test_x\u001b[38;5;241m.\u001b[39mretain_grad()\n",
      "\u001b[0;31mAttributeError\u001b[0m: __enter__"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plots\n",
    "f, (y1_ax, y2_ax) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# Make predictions\n",
    "with 1:#torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(0, 1, 51)\n",
    "#     test_x.retain_grad()\n",
    "    predictions = likelihood(model(test_x))\n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "\n",
    "# This contains predictions for both tasks, flattened out\n",
    "# The first half of the predictions is for the first task\n",
    "# The second half is for the second task\n",
    "\n",
    "# Plot training data as black stars\n",
    "y1_ax.plot(train_x.detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y1_ax.plot(test_x.numpy(), mean[:, 0].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y1_ax.fill_between(test_x.numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "y1_ax.set_ylim([-3, 3])\n",
    "y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# Plot training data as black stars\n",
    "y2_ax.plot(train_x.detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# Predictive mean as blue line\n",
    "y2_ax.plot(test_x.numpy(), mean[:, 1].numpy(), 'b')\n",
    "# Shade in confidence\n",
    "y2_ax.fill_between(test_x.numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "y2_ax.set_ylim([-3, 3])\n",
    "y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "y2_ax.set_title('Observed Values (Likelihood)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb2a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "556048e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2.0], dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3af6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a + torch.tensor([1.0],dtype=torch.float)\n",
    "a.retain_grad()\n",
    "y = torch.square(a - torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acf107fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c7a00a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64fbe3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d381a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2.0], dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e3cfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.square(a - torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b3d4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([5.0], dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f55beffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = a - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33b48ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03853b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f49715c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed524511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
